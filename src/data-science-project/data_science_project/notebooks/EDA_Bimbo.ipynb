{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NicoG2023/Data_Science_Final_Project/blob/Predata/src/data-science-project/data_science_project/notebooks/EDA_Rain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-PhuzxGDPEXZ"
      },
      "source": [
        "# EDA \"Grupo Bimbo Inventory Demand\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dIQTcBMFPEXj"
      },
      "source": [
        "### Introduction\n",
        "\n",
        "Grupo Bimbo, a leading multinational bakery company, faces a unique challenge in managing the inventory of its products. With a typical shelf life of just one week, the accuracy of daily inventory calculations is paramount. Currently, these calculations are performed by direct delivery sales employees who rely on their personal experiences to predict the forces of supply, demand, and consumer behavior at each store. The margin for error in this process is minimal. Underestimating demand results in empty shelves and lost sales, while overestimating demand leads to excess product returns and increased expenses.\n",
        "\n",
        "Grupo Bimbo aims to create a predictive model that can accurately forecast inventory needs based on historical data, thereby optimizing the supply chain and improving efficiency.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oHvVr32yPEXm"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "hCwTZNhrPEXm",
        "outputId": "d86636f4-a2d9-4686-c765-90d100005fa6"
      },
      "outputs": [],
      "source": [
        "# importing the basic libraries\n",
        "#!pip install ydata_profiling\n",
        "# !pip install catboost\n",
        "# !pip install lightgbm\n",
        "# !pip install xgboost\n",
        "# !pip install plotly\n",
        "# !pip install path\n",
        "from ydata_profiling import ProfileReport\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "# from sklearn.metrics import roc_auc_score, accuracy_score\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# from sklearn.metrics import accuracy_score\n",
        "# from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
        "# from sklearn.linear_model import LogisticRegression\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.neighbors import KNeighborsClassifier\n",
        "# from sklearn.tree import DecisionTreeClassifier, ExtraTreeClassifier\n",
        "# from xgboost import XGBClassifier\n",
        "# from lightgbm import LGBMClassifier\n",
        "# from catboost import CatBoostClassifier\n",
        "# import path\n",
        "import os\n",
        "# import plotly.express as px\n",
        "import gc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8-BRpWWPEXq"
      },
      "source": [
        "## Charge data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3cy1r5QSPEXr"
      },
      "outputs": [],
      "source": [
        "train_df = pd.read_csv(\"../Data/train/train.csv\",nrows=1000)\n",
        "client_df = pd.read_csv(\"../Data/cliente_tabla.csv\")\n",
        "products_df = pd.read_csv(\"../Data/producto_tabla.csv\")\n",
        "test_df = pd.read_csv(\"../Data/test/test.csv\")\n",
        "town_state_df = pd.read_csv(\"../Data/town_state.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Uemom6AgrfQ"
      },
      "outputs": [],
      "source": [
        "# Inspect the data, with funcion\n",
        "\n",
        "def inspect_columns(df:pd.DataFrame, df_name:str)->None:\n",
        "    \"\"\"\n",
        "    A helper function that does a deep analisis about the columns in a dataframe\n",
        "    Inputs:\n",
        "     df(pd.Dataframe): the dataframe that will be inspected\n",
        "     df_name(str): the tittle that will be put in the output(print) of the function\n",
        "    Returns:\n",
        "     None\n",
        "    \"\"\"\n",
        "\n",
        "    total_rows = len(df)\n",
        "    result = pd.DataFrame({\n",
        "        'total_rows': [total_rows] * df.shape[1],\n",
        "        'rows_with_missing_values': df.isnull().sum(),\n",
        "        'unique': df.nunique() == total_rows,\n",
        "        'cardinality': df.nunique(),\n",
        "        'with_null': df.isna().any(),\n",
        "        'null_pct': round((df.isnull().sum() / total_rows) * 100, 2),\n",
        "        '1st_row': df.iloc[0],\n",
        "        'random_row': df.iloc[np.random.randint(low=0, high=total_rows)],\n",
        "        'last_row': df.iloc[-1],\n",
        "        'dtype': df.dtypes,\n",
        "    })\n",
        "\n",
        "    # Print the name of the dataframe\n",
        "    print(f\"\\n{'='*10} {df_name} {'='*10}\\n\")\n",
        "\n",
        "    # Print the head of the dataframe\n",
        "    print(\"First few rows of the dataframe:\\n\")\n",
        "    display(df.head())\n",
        "\n",
        "    # Print the resulting statistics\n",
        "    print(\"Detailed statistics:\\n\")\n",
        "    display(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dV2MDNKqPEXt"
      },
      "source": [
        "## Understand the data\n",
        "\n",
        "We performed a preliminary exploration to understand the structure of the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-_SdP2IOPEXu",
        "outputId": "1980567a-1756-4699-b77c-cb25b0621bda"
      },
      "outputs": [],
      "source": [
        "inspect_columns(train_df,\"Training Dataframe\")\n",
        "inspect_columns(client_df,\"Client Dataframe\")\n",
        "inspect_columns(products_df,\"Products Dataframe\")\n",
        "inspect_columns(test_df,\"Test Dataframe\")\n",
        "inspect_columns(town_state_df,\"Town and State Dataframe\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iy99vpHcPEXx"
      },
      "source": [
        "### Exploratory data analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0-uglQX_PEXy"
      },
      "outputs": [],
      "source": [
        "# transform by merge with the data\n",
        "\n",
        "train_df = train_df.merge(client_df,on = \"Cliente_ID\",how=\"left\")\n",
        "train_df = train_df.merge(products_df,on = \"Producto_ID\",how=\"left\")\n",
        "train_df = train_df.merge(town_state_df,on = \"Agencia_ID\",how=\"left\")\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nwrsHoYEgrfS"
      },
      "outputs": [],
      "source": [
        "# translate the language used for the data\n",
        "\n",
        "train_df = train_df.rename({'Semana':'Week', 'Agencia_ID':'Sales_Depot_ID', 'Canal_ID':'Sales_Channel_ID', 'Ruta_SAK':'Route_ID', 'Cliente_ID':'Client_ID',\n",
        "       'Producto_ID':'Product_ID', 'Venta_uni_hoy':'Sales_unit_this_week ', 'Venta_hoy':'Sales_this_week', 'Dev_uni_proxima':'Returns_unit_next_week',\n",
        "       'Dev_proxima':'Returns_next_week', 'Demanda_uni_equil':'Adjusted_Demand', 'NombreCliente':'Client_name', 'NombreProducto':'Product_Name',\n",
        "       'Town':'Town', 'State':'State'},axis=1)\n",
        "\n",
        "train_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HpcLwalTjdzZ"
      },
      "outputs": [],
      "source": [
        "# inspect the data with ydata profile\n",
        "sample_df = train_df.sample(frac=0.2, random_state=1)\n",
        "profile_obj = ProfileReport(sample_df, title='Bimbo Inventory Demand Data Profiling Report', minimal=True)\n",
        "profile_obj.to_file('../Data/html-files/train_final_minimal.html')\n",
        "profile_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "profile_obj = ProfileReport(sample_df, title='Bimbo Inventory Demand Data Profiling Report')\n",
        "profile_obj.to_file('../Data/html-files/train_final_normal.html')\n",
        "profile_obj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_df = train_df.sample(frac=0.1, random_state=1)\n",
        "profile_obj = ProfileReport(sample_df, title='Bimbo Inventory Demand Data Profiling Report', explorative=True)\n",
        "profile_obj.to_file('../Data/html-files/train_final_explorative.html')\n",
        "profile_obj"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Web Scraping\n",
        "\n",
        "According to the dataset, the data was taken in a timespan of 9 weeks. It's been decided to get the biweekly inflation and the consumer confidence index from Mexico. The info was taken from March 31st, 2016, until June 1st, 2016."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Getting biweekly inflation\n",
        "import sys\n",
        "import requests\n",
        "from datetime import datetime\n",
        "\n",
        "api_key = '74bcad49-835f-fab1-c9f0-fdab92570186'\n",
        "\n",
        "api_url = f'https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/628229/es/0700/false/BIE/2.0/{api_key}?type=json'\n",
        "\n",
        "response = requests.get(api_url)\n",
        "if response.status_code == 200:\n",
        "    inflation_data = response.json()\n",
        "else:\n",
        "    print('ERROR FAILED TO RETRIEVE DATA')\n",
        "    sys.exit()\n",
        "\n",
        "observations = inflation_data['Series'][0]['OBSERVATIONS']\n",
        "dates = []\n",
        "values = []\n",
        "for obs in observations:\n",
        "    dates.append(obs['TIME_PERIOD'])\n",
        "    values.append(obs['OBS_VALUE'])\n",
        "\n",
        "inflation_df = pd.DataFrame({\n",
        "    'Fecha': dates,\n",
        "    'Inflacion': values\n",
        "})\n",
        "\n",
        "inflation_df['Fecha'] = pd.to_datetime(inflation_df['Fecha'], format='%Y/%m/%d')\n",
        "start_date = datetime(2016, 3, 31)\n",
        "end_date = datetime(2016, 6, 1)\n",
        "\n",
        "filtered_inflation_df = inflation_df[(inflation_df['Fecha'] >= start_date) & (inflation_df['Fecha'] <= end_date)]\n",
        "filtered_inflation_df = filtered_inflation_df.reset_index(drop=True)\n",
        "filtered_inflation_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#Getting consumer confidence index\n",
        "api_key = '74bcad49-835f-fab1-c9f0-fdab92570186'\n",
        "api_url = f'https://www.inegi.org.mx/app/api/indicadores/desarrolladores/jsonxml/INDICATOR/454168/es/0700/false/BIE/2.0/{api_key}?type=json'\n",
        "\n",
        "response = requests.get(api_url)\n",
        "if response.status_code == 200:\n",
        "    confidence_data = response.json()\n",
        "else:\n",
        "    print('ERROR FAILED TO RETRIEVE DATA')\n",
        "    sys.exit()\n",
        "\n",
        "observations = confidence_data['Series'][0]['OBSERVATIONS']\n",
        "dates = []\n",
        "values = []\n",
        "\n",
        "for obs in observations:\n",
        "    dates.append(obs['TIME_PERIOD'])\n",
        "    values.append(obs['OBS_VALUE'])\n",
        "\n",
        "confidence_data = pd.DataFrame({\n",
        "    'Fecha': dates,\n",
        "    'Consumer_confidence': values\n",
        "})\n",
        "\n",
        "confidence_data['Fecha'] = pd.to_datetime(confidence_data['Fecha'], format='%Y/%m')\n",
        "start_date = datetime(2016, 3, 31)\n",
        "end_date = datetime(2016, 6, 1)\n",
        "\n",
        "filtered_confidence_df = confidence_data[(confidence_data['Fecha'] >= start_date) & (confidence_data['Fecha'] <= end_date)]\n",
        "filtered_confidence_df = filtered_confidence_df.reset_index(drop=True)\n",
        "filtered_confidence_df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Merging\n",
        "Having charged and understood the data now we proceed to merge it in order to create a consise and rich dataset for the model to be given "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1025 entries, 0 to 1024\n",
            "Data columns (total 18 columns):\n",
            " #   Column                  Non-Null Count  Dtype         \n",
            "---  ------                  --------------  -----         \n",
            " 0   Week                    1025 non-null   int64         \n",
            " 1   Sales_Depot_ID          1025 non-null   int64         \n",
            " 2   Sales_Channel_ID        1025 non-null   int64         \n",
            " 3   Route_ID                1025 non-null   int64         \n",
            " 4   Client_ID               1025 non-null   int64         \n",
            " 5   Product_ID              1025 non-null   int64         \n",
            " 6   Sales_unit_this_week    1025 non-null   int64         \n",
            " 7   Sales_this_week         1025 non-null   float64       \n",
            " 8   Returns_unit_next_week  1025 non-null   int64         \n",
            " 9   Returns_next_week       1025 non-null   float64       \n",
            " 10  Adjusted_Demand         1025 non-null   int64         \n",
            " 11  Client_name             1025 non-null   object        \n",
            " 12  Product_Name            1025 non-null   object        \n",
            " 13  Town                    1025 non-null   object        \n",
            " 14  State                   1025 non-null   object        \n",
            " 15  Fecha                   5 non-null      datetime64[ns]\n",
            " 16  Consumer_confidence     3 non-null      object        \n",
            " 17  Inflacion               5 non-null      object        \n",
            "dtypes: datetime64[ns](1), float64(2), int64(9), object(6)\n",
            "memory usage: 144.3+ KB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# merging train_df, filtered_confidence_df, filtered_inflation_df\n",
        "webs_df = pd.merge(filtered_confidence_df,filtered_inflation_df,on=\"Fecha\",how=\"outer\")\n",
        "final_df = pd.concat([train_df,webs_df],axis=1)\n",
        "\n",
        "print(final_df.info())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))  # Adjust figure size as needed\n",
        "plt.barh(final_df[\"Product_Name\"], final_df[\"Sales_this_week\"])\n",
        "plt.title(\"Sales per Product\")\n",
        "plt.xlabel(\"Sales\")\n",
        "plt.ylabel(\"Product Name\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sns.lmplot(x=\"Sales_this_week\",y=\"Returns_next_week\",data=final_df)\n",
        "plt.title(\"Expected Demand\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "plt.scatter(final_df[\"Sales_this_week\"],final_df[\"Client_name\"],color=\"r\",label=\"Sales\")\n",
        "plt.scatter(final_df[\"Returns_next_week\"],final_df[\"Client_name\"],color=\"b\",label=\"Refund\")\n",
        "plt.legend()\n",
        "plt.title(\"Sales and Refunds per Client\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(final_df[])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20,20))\n",
        "plt.scatter(final_df[\"Sales_this_week\"],final_df[\"Client_name\"],color=\"r\",label=\"Sales\")\n",
        "plt.scatter(final_df[\"Returns_next_week\"],final_df[\"Client_name\"],color=\"b\",label=\"Refund\")\n",
        "plt.legend()\n",
        "plt.title(\"Sales and Refunds per Client\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.figure(figsize=(20, 20))  # Adjust figure size as needed\n",
        "plt.barh(final_df[\"Product_Name\"], final_df[\"Sales_this_week\"])\n",
        "plt.title(\"Sales per Product\")\n",
        "plt.xlabel(\"Sales\")\n",
        "plt.ylabel(\"Product Name\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
